{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hotel_reviews_sentiment_analysis_lstm.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOQsfVRHuh80PUMB2cUPJ22",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adi8885/RecurrentNets/blob/master/Hotel_reviews_sentiment_analysis_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rtsgzGuPUza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as Dataset\n",
        "import torch.autograd as autograd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "\n",
        "\n",
        "import nltk\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import classification_report , accuracy_score , confusion_matrix\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epurxfGcgyYb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "8bed64e2-ae94-4218-a6c1-b6ce3926bedd"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Mar 22 14:02:55 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8    25W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkisaWciPruI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "36d84a3e-10e9-4813-b09b-9cfdd52c562e"
      },
      "source": [
        "data = pd.read_csv('./Hotel_Reviews_small.csv'\n",
        "                   , low_memory = False \n",
        "                   , compression = 'gzip'\n",
        "                   , nrows = 100000\n",
        "                   )\n",
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>liked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Good location near metro station The room was...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>We did not know it was 2 single beds never se...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The porters where very polite and helpful</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wifi was not working properly and no mobile s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The WC Bath had not fan to let air out so som...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  liked\n",
              "0   Good location near metro station The room was...      1\n",
              "1   We did not know it was 2 single beds never se...      0\n",
              "2         The porters where very polite and helpful       1\n",
              "3   Wifi was not working properly and no mobile s...      0\n",
              "4   The WC Bath had not fan to let air out so som...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ancf0JAzP1Gu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "3c7cd886-b326-4cdc-ec4d-5e233b705a83"
      },
      "source": [
        "#remove html Tags\n",
        "\n",
        "st_time = time.time()\n",
        "data['review'] = data['review'].str.lower()\n",
        "data['review'] = data['review'].str.replace('<br','')\n",
        "data['review'] = data['review'].str.replace('/>','')\n",
        "data['review'] = data['review'].str.replace('[^\\w\\s]','')\n",
        "\n",
        "#remove html Tags\n",
        "special_chars = \"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"\n",
        "data['review'] = data['review'].apply(lambda x: \" \".join(x for x in x.split() if x not in special_chars))\n",
        "\n",
        "#remove numbers\n",
        "numbers = '0123456789'\n",
        "data['review'] = data['review'].apply(lambda x: \" \".join(x for x in x.split() if x not in numbers))\n",
        "\n",
        "\n",
        "#Remove stopwords\n",
        "#stop = stopwords.words('english')\n",
        "#data['review'] = data['review'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "\n",
        "print(' time taken to process : {} seconds'.format(round(time.time() - st_time ,2)))\n",
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " time taken to process : 1.35 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>liked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>good location near metro station the room was ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>we did not know it was single beds never seen ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the porters where very polite and helpful</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>wifi was not working properly and no mobile si...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>the wc bath had not fan to let air out so some...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  liked\n",
              "0  good location near metro station the room was ...      1\n",
              "1  we did not know it was single beds never seen ...      0\n",
              "2          the porters where very polite and helpful      1\n",
              "3  wifi was not working properly and no mobile si...      0\n",
              "4  the wc bath had not fan to let air out so some...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVj8dwtgP2rW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "caa174e8-36c8-42e4-ac99-5737b62f3c34"
      },
      "source": [
        "data['review_length'] = data['review'].apply(lambda x: len(str(x).split(\" \")))\n",
        "data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>liked</th>\n",
              "      <th>review_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>good location near metro station the room was ...</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>we did not know it was single beds never seen ...</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the porters where very polite and helpful</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>wifi was not working properly and no mobile si...</td>\n",
              "      <td>0</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>the wc bath had not fan to let air out so some...</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  liked  review_length\n",
              "0  good location near metro station the room was ...      1             42\n",
              "1  we did not know it was single beds never seen ...      0             12\n",
              "2          the porters where very polite and helpful      1              7\n",
              "3  wifi was not working properly and no mobile si...      0             43\n",
              "4  the wc bath had not fan to let air out so some...      0             37"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p69FKpTxQAAP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "19fc12ba-746b-4c65-9bd3-abbc2b6e9849"
      },
      "source": [
        "print('min sentence Length : {}'.format(data.review_length.min()))\n",
        "print('max sentence Length : {}'.format(data.review_length.max()))\n",
        "print('mean sentence Length : {}'.format(data.review_length.mean()))\n",
        "print('median sentence Length : {}'.format(data.review_length.median()))\n",
        "\n",
        "data['review_length'].describe(percentiles = [0.25 , 0.5 , 0.75 , 0.9 , 0.95 , 0.99])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "min sentence Length : 1\n",
            "max sentence Length : 390\n",
            "mean sentence Length : 19.81121\n",
            "median sentence Length : 12.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    100000.000000\n",
              "mean         19.811210\n",
              "std          26.418168\n",
              "min           1.000000\n",
              "25%           5.000000\n",
              "50%          12.000000\n",
              "75%          24.000000\n",
              "90%          45.000000\n",
              "95%          64.000000\n",
              "99%         127.000000\n",
              "max         390.000000\n",
              "Name: review_length, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmupVSTEQFBm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2abe447e-88f6-4f50-e34c-32b6ac54eb96"
      },
      "source": [
        "st_time = time.time()\n",
        "sentence_corpus = []\n",
        "for i in data.review:\n",
        "    sentence_corpus.append(i.split())\n",
        "len(sentence_corpus)\n",
        "print('time taken to process : {} seconds'.format(round(time.time() - st_time ,2)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time taken to process : 0.35 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjNxFr1tQHv9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "63bdf2a2-fcad-4d30-b05f-eb8d8507ae1e"
      },
      "source": [
        "st_time = time.time()\n",
        "vocab = []\n",
        "for i in data.review:\n",
        "    for j in i.split():\n",
        "        if j not in vocab:\n",
        "            vocab.append(j)\n",
        "vocab_size = len(vocab)\n",
        "print('vocab_size : {}'.format(vocab_size))\n",
        "print('time taken to process : {} seconds'.format(round(time.time() - st_time ,2)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab_size : 26867\n",
            "time taken to process : 21.96 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8bvnzZHQKwa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d9fba37f-7107-42d6-afdd-70317e236de8"
      },
      "source": [
        "st_time = time.time()\n",
        "word_to_idx = {}\n",
        "idx_to_word = {}\n",
        "for i in enumerate(vocab):\n",
        "    #print(i)\n",
        "    word_to_idx[i[1]] = i[0]\n",
        "    idx_to_word[i[0]] = i[1]\n",
        "print(len(word_to_idx))\n",
        "print(len(idx_to_word))\n",
        "print('time taken to map vocab : {} seconds'.format(round(time.time() - st_time ,2)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26867\n",
            "26867\n",
            "time taken to map vocab : 0.02 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YO9JJPADQNQw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ccbeb9a-6666-49d3-cf46-1a39d7e761ec"
      },
      "source": [
        "max_sentence_length = 64\n",
        "seq_len = max_sentence_length\n",
        "print('max_sentence_length : {}'.format(max_sentence_length))\n",
        "for i in range(0,len(sentence_corpus)):\n",
        "    sentence = sentence_corpus[i]\n",
        "    if len(sentence) < max_sentence_length :\n",
        "        padding_length = max_sentence_length - len(sentence)\n",
        "        #print(padding_length)\n",
        "        for j in range(len(sentence) , max_sentence_length) :\n",
        "            sentence.append('<>')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max_sentence_length : 64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIpVcnMzQSpN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e75f0b9-2113-457f-c48d-0c8924c4a7e1"
      },
      "source": [
        "vec_size = 128\n",
        "st_time = time.time()\n",
        "word2vec = Word2Vec(sentence_corpus, window=5 , min_count=1, size=vec_size , workers=12)\n",
        "print('time taken to train word2vec : {} seconds'.format(round(time.time() - st_time ,2)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time taken to train word2vec : 19.3 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVT9S3r7QWDq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorize_sentence(sentence):\n",
        "    sentence = sentence.split()\n",
        "    input_data = np.zeros((seq_len,vec_size))\n",
        "    #print(corpus)\n",
        "    k = 0\n",
        "    for i in sentence:\n",
        "        if k < seq_len : \n",
        "            if i == '<>':\n",
        "                word_vector = np.zeros(vec_size)\n",
        "            else:\n",
        "                word_vector = word2vec.wv[i] \n",
        "            input_data[k] = word_vector\n",
        "        else:\n",
        "            continue\n",
        "        k+=1\n",
        "        #print(i)\n",
        "    return input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFERoCmgQYV3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c452534-acee-4aea-ce68-bce3354ce677"
      },
      "source": [
        "Y = data.liked.values\n",
        "Y.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tf-n5zXQZ-z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "098513b9-d42d-48db-d7dd-3b33b0026cc3"
      },
      "source": [
        "X = []\n",
        "print_every = 10000\n",
        "ctr = 0\n",
        "st_time = time.time()\n",
        "total_records = data.shape[0]\n",
        "for idx in data.index :\n",
        "    text = data.loc[idx].review\n",
        "    feature = vectorize_sentence(text)\n",
        "    X.append(feature)\n",
        "    ctr+=1\n",
        "    if ctr % print_every == 0 :\n",
        "        print('records done : {}/{} \\t time : {}'.format(ctr , total_records , round(time.time() - st_time ,2)))\n",
        "        st_time = time.time()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "records done : 10000/100000 \t time : 3.97\n",
            "records done : 20000/100000 \t time : 3.97\n",
            "records done : 30000/100000 \t time : 3.91\n",
            "records done : 40000/100000 \t time : 3.92\n",
            "records done : 50000/100000 \t time : 3.92\n",
            "records done : 60000/100000 \t time : 3.92\n",
            "records done : 70000/100000 \t time : 3.95\n",
            "records done : 80000/100000 \t time : 3.97\n",
            "records done : 90000/100000 \t time : 3.87\n",
            "records done : 100000/100000 \t time : 3.91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16AnOSOBQd95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#total_records = X.shape[0]\n",
        "train_percent = 0.9\n",
        "val_percent = 0.05\n",
        "test_percent = (1 - (train_percent + val_percent))\n",
        "\n",
        "train_idx = int(train_percent * total_records)\n",
        "test_idx = int(test_percent * total_records)\n",
        "val_idx = int(val_percent * total_records)\n",
        "\n",
        "x_train = X[0 : train_idx]\n",
        "y_train = Y[0 : train_idx]\n",
        "#print( ' x_train : {}  y_train : {}'.format(x_train.shape , y_train.shape))\n",
        "\n",
        "x_val = X[ train_idx : (train_idx + val_idx)]\n",
        "y_val = Y[ train_idx : (train_idx + val_idx)]\n",
        "#print( ' x_val : {}  y_val : {}'.format(x_val.shape , y_val.shape))\n",
        "\n",
        "x_test = X[(train_idx + val_idx) : ]\n",
        "y_test = Y[(train_idx + val_idx) : ]\n",
        "#print( ' x_test : {}  y_test : {}'.format(x_test.shape , y_test.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5gwQnw0QjiK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 100\n",
        "\n",
        "x_train = torch.tensor(x_train)\n",
        "y_train = torch.tensor(y_train)\n",
        "train_dataset = torch.utils.data.TensorDataset(x_train ,y_train)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "x_val = torch.tensor(x_val)\n",
        "y_val = torch.tensor(y_val)\n",
        "val_dataset = torch.utils.data.TensorDataset(x_val ,y_val)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "x_test = torch.tensor(x_test)\n",
        "y_test = torch.tensor(y_test)\n",
        "test_dataset = torch.utils.data.TensorDataset(x_test ,y_test)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyKtOYgKQsr8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "81cabf0e-cba9-4290-eba3-d0add6ccacf9"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('CUDA available, training on GPU')\n",
        "else :\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('cuda NOT available, training on CPU') \n",
        "    \n",
        "#device = torch.device(\"cpu\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA available, training on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEa1aedfQvmC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "8e3be5fd-33dc-408b-e39d-6e79bee2a99c"
      },
      "source": [
        "input_size = vec_size\n",
        "hidden_size = vec_size\n",
        "num_layers = 1\n",
        "batch_size = batch_size\n",
        "drop_out_probability = 0.25\n",
        "\n",
        "output_size = 2\n",
        "\n",
        "\n",
        "class NN_Classifier(nn.Module):\n",
        "    def __init__(self , input_size , hidden_size , num_layers , output_size):\n",
        "        super(NN_Classifier ,self).__init__()\n",
        "        \n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "        \n",
        "        #lstm layer\n",
        "        self.lstm1 = nn.LSTM(input_size = input_size\n",
        "                             , hidden_size = hidden_size \n",
        "                             , num_layers = num_layers\n",
        "                             , batch_first = True \n",
        "                             #,dropout=drop_out_probability\n",
        "                             )\n",
        "        \n",
        "        # Inputs to hidden layer linear transformation\n",
        "        self.fc1 = nn.Linear(in_features = input_size , out_features = hidden_size)\n",
        "        \n",
        "        #Droput layer before output\n",
        "        #self.dropout1 = nn.Dropout(p = drop_out_probability)\n",
        "        \n",
        "        # Output layer, 10 units - one for each digit\n",
        "        self.out = nn.Linear(in_features = hidden_size , out_features = output_size)\n",
        "        \n",
        "    def _init_hidden(self,batch_size):\n",
        "        hidden = torch.zeros((self.num_layers, batch_size , self.hidden_size),dtype = torch.float64)\n",
        "        c_0 = torch.zeros((self.num_layers, batch_size , self.hidden_size),dtype = torch.float64)\n",
        "        return hidden.to(device) , c_0.to(device)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        \n",
        "        #create initial hidden layer of zeros and intial state of zeros\n",
        "        hidden , c_0 = self._init_hidden(batch_size)\n",
        "        \n",
        "        # Pass the input tensor through LSTM\n",
        "        lstm_out ,hidden = self.lstm1(x,(hidden,c_0))\n",
        "        \n",
        "        #Transpose tensor before feeding into Linear layer\n",
        "        lstm_out = lstm_out.transpose(dim0 = 0, dim1 = 1)\n",
        "        x = self.fc1(lstm_out[-1])\n",
        "        \n",
        "        #Dropout layer\n",
        "        #x = self.dropout1(x)\n",
        "        \n",
        "        #Fully connected layer\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        #Output layer\n",
        "        x = self.out(x)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "model = NN_Classifier(input_size = input_size \n",
        "                        , hidden_size = hidden_size\n",
        "                        , output_size = output_size\n",
        "                        , num_layers = num_layers)\n",
        "model.double()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NN_Classifier(\n",
              "  (lstm1): LSTM(128, 128, batch_first=True)\n",
              "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
              "  (out): Linear(in_features=128, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y2nNJXBQzi7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6a2b3cdf-1d4e-4d94-e9f8-0a0faf5aa1dd"
      },
      "source": [
        "epochs = 10\n",
        "loss_fn = F.cross_entropy\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "print_every = 100\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "# to track the average training loss per epoch as the model trains\n",
        "avg_train_losses = []\n",
        "# to track the average validation loss per epoch as the model trains\n",
        "avg_valid_losses = [] \n",
        "patience_ctr = 0\n",
        "patience = 2\n",
        "\n",
        "\n",
        "st_time = time.time()\n",
        "    \n",
        "for epoch in range(0,epochs):\n",
        "    \n",
        "    # to track the training loss as the model trains\n",
        "    train_losses = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_losses = []\n",
        "\n",
        "    batch = 0\n",
        "    #loss = 0\n",
        "    st_time = time.time()\n",
        "    model.train()\n",
        "    for x, y in train_dataloader :\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(x)\n",
        "        \n",
        "        #y_pred = y_pred.unsqueeze(0)\n",
        "        loss = loss_fn(y_pred , y)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_losses.append(loss.item())\n",
        "        \n",
        "        if (batch % print_every == 0):\n",
        "            print('epoch: {}/{}\\tbatch: {}/{}\\ttrain loss : {}\\ttime : {} secs '.format(epoch, \n",
        "                                                                                       epochs , \n",
        "                                                                                       batch,\n",
        "                                                                                       len(train_dataloader) , \n",
        "                                                                                       loss.item() , \n",
        "                                                                                       round(time.time() - st_time , 2)))\n",
        "            \n",
        "        batch +=1\n",
        "\n",
        "    #Calculate Validation loss\n",
        "    val_acc = 0\n",
        "    model = model.eval()\n",
        "    for x_v, y_v in val_dataloader :\n",
        "        x_v = x_v.to(device)\n",
        "        y_v = y_v.to(device)\n",
        "        \n",
        "        y_pred = model(x_v)\n",
        "        loss = loss_fn(y_pred , y_v)\n",
        "        \n",
        "        valid_losses.append(loss.item())\n",
        "    \n",
        "    # calculate average loss over an epoch\n",
        "    train_loss = np.average(train_losses)\n",
        "    valid_loss = np.average(valid_losses)\n",
        "    avg_train_losses.append(train_loss)\n",
        "    avg_valid_losses.append(valid_loss)\n",
        "\n",
        "    #Early stopping\n",
        "    if valid_loss > train_loss:\n",
        "        patience_ctr +=1\n",
        "        print('patience_ctr : {}'.format(patience_ctr))\n",
        "        if patience_ctr >= patience:\n",
        "            print('early stoppping since valid_loss > train_loss')\n",
        "            break\n",
        "    else :\n",
        "        patience_ctr = 0\n",
        "    \n",
        "    epoch_len = len(str(epochs))\n",
        "    print('\\nepoch : {}/{}\\t train_loss :{}\\t validation loss : {}\\n'.format(epoch , \n",
        "                                                                           epochs, \n",
        "                                                                           train_loss , \n",
        "                                                                           valid_loss))\n",
        "    \n",
        "            \n",
        "    print('epoch : {}/{} \\t train loss : {} \\t time required : {} secs'.format(epoch, \n",
        "                                                                          epochs, \n",
        "                                                                          loss.item(),\n",
        "                                                                          round(time.time() - st_time , 2)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0/10\tbatch: 0/900\ttrain loss : 0.693786823440071\ttime : 0.34 secs \n",
            "epoch: 0/10\tbatch: 100/900\ttrain loss : 0.5492039980671309\ttime : 2.75 secs \n",
            "epoch: 0/10\tbatch: 200/900\ttrain loss : 0.45184258246865583\ttime : 5.07 secs \n",
            "epoch: 0/10\tbatch: 300/900\ttrain loss : 0.4632369970354426\ttime : 7.4 secs \n",
            "epoch: 0/10\tbatch: 400/900\ttrain loss : 0.5798667255801766\ttime : 9.69 secs \n",
            "epoch: 0/10\tbatch: 500/900\ttrain loss : 0.33418520571833304\ttime : 12.01 secs \n",
            "epoch: 0/10\tbatch: 600/900\ttrain loss : 0.4714941705065928\ttime : 14.31 secs \n",
            "epoch: 0/10\tbatch: 700/900\ttrain loss : 0.27115657529478804\ttime : 16.61 secs \n",
            "epoch: 0/10\tbatch: 800/900\ttrain loss : 0.24425074726924847\ttime : 18.91 secs \n",
            "\n",
            "epoch : 0/10\t train_loss :0.4121986127866022\t validation loss : 0.2703127577632303\n",
            "\n",
            "epoch : 0/10 \t train loss : 0.30750150443435326 \t time required : 22.25 secs\n",
            "epoch: 1/10\tbatch: 0/900\ttrain loss : 0.17957530737340746\ttime : 0.34 secs \n",
            "epoch: 1/10\tbatch: 100/900\ttrain loss : 0.23162534866475215\ttime : 2.61 secs \n",
            "epoch: 1/10\tbatch: 200/900\ttrain loss : 0.2686118098890842\ttime : 4.87 secs \n",
            "epoch: 1/10\tbatch: 300/900\ttrain loss : 0.2621565181504852\ttime : 7.18 secs \n",
            "epoch: 1/10\tbatch: 400/900\ttrain loss : 0.211399556786422\ttime : 9.45 secs \n",
            "epoch: 1/10\tbatch: 500/900\ttrain loss : 0.39996996569007903\ttime : 11.74 secs \n",
            "epoch: 1/10\tbatch: 600/900\ttrain loss : 0.2505144909232864\ttime : 14.04 secs \n",
            "epoch: 1/10\tbatch: 700/900\ttrain loss : 0.24538180993960168\ttime : 16.36 secs \n",
            "epoch: 1/10\tbatch: 800/900\ttrain loss : 0.17831751895708575\ttime : 18.67 secs \n",
            "\n",
            "epoch : 1/10\t train_loss :0.22532370813060096\t validation loss : 0.18163257965641505\n",
            "\n",
            "epoch : 1/10 \t train loss : 0.19705558511260107 \t time required : 21.99 secs\n",
            "epoch: 2/10\tbatch: 0/900\ttrain loss : 0.2943082438105345\ttime : 0.33 secs \n",
            "epoch: 2/10\tbatch: 100/900\ttrain loss : 0.18917868562428297\ttime : 2.59 secs \n",
            "epoch: 2/10\tbatch: 200/900\ttrain loss : 0.2591800445440471\ttime : 4.87 secs \n",
            "epoch: 2/10\tbatch: 300/900\ttrain loss : 0.2588460746290476\ttime : 7.17 secs \n",
            "epoch: 2/10\tbatch: 400/900\ttrain loss : 0.13883878950277478\ttime : 9.45 secs \n",
            "epoch: 2/10\tbatch: 500/900\ttrain loss : 0.08248542217745075\ttime : 11.74 secs \n",
            "epoch: 2/10\tbatch: 600/900\ttrain loss : 0.18064430444972185\ttime : 14.02 secs \n",
            "epoch: 2/10\tbatch: 700/900\ttrain loss : 0.15513145182227026\ttime : 16.31 secs \n",
            "epoch: 2/10\tbatch: 800/900\ttrain loss : 0.14811606886626144\ttime : 18.6 secs \n",
            "\n",
            "epoch : 2/10\t train_loss :0.16968416754451993\t validation loss : 0.16488658121985783\n",
            "\n",
            "epoch : 2/10 \t train loss : 0.16942944035082877 \t time required : 21.92 secs\n",
            "epoch: 3/10\tbatch: 0/900\ttrain loss : 0.14664751037948473\ttime : 0.33 secs \n",
            "epoch: 3/10\tbatch: 100/900\ttrain loss : 0.16130155516259326\ttime : 2.61 secs \n",
            "epoch: 3/10\tbatch: 200/900\ttrain loss : 0.1059579404410039\ttime : 4.91 secs \n",
            "epoch: 3/10\tbatch: 300/900\ttrain loss : 0.1365437742526802\ttime : 7.2 secs \n",
            "epoch: 3/10\tbatch: 400/900\ttrain loss : 0.12521962862575525\ttime : 9.49 secs \n",
            "epoch: 3/10\tbatch: 500/900\ttrain loss : 0.19367747685469727\ttime : 11.77 secs \n",
            "epoch: 3/10\tbatch: 600/900\ttrain loss : 0.20145128502675033\ttime : 14.06 secs \n",
            "epoch: 3/10\tbatch: 700/900\ttrain loss : 0.24001090815246315\ttime : 16.35 secs \n",
            "epoch: 3/10\tbatch: 800/900\ttrain loss : 0.08930804486561537\ttime : 18.64 secs \n",
            "\n",
            "epoch : 3/10\t train_loss :0.15401334868629526\t validation loss : 0.14644971085385475\n",
            "\n",
            "epoch : 3/10 \t train loss : 0.1124986836510435 \t time required : 21.95 secs\n",
            "epoch: 4/10\tbatch: 0/900\ttrain loss : 0.11081270154168867\ttime : 0.33 secs \n",
            "epoch: 4/10\tbatch: 100/900\ttrain loss : 0.2380790577353307\ttime : 2.59 secs \n",
            "epoch: 4/10\tbatch: 200/900\ttrain loss : 0.10972972056299735\ttime : 4.87 secs \n",
            "epoch: 4/10\tbatch: 300/900\ttrain loss : 0.08990195584894954\ttime : 7.18 secs \n",
            "epoch: 4/10\tbatch: 400/900\ttrain loss : 0.1779175937361573\ttime : 9.5 secs \n",
            "epoch: 4/10\tbatch: 500/900\ttrain loss : 0.20538350310218376\ttime : 11.81 secs \n",
            "epoch: 4/10\tbatch: 600/900\ttrain loss : 0.1668092872241261\ttime : 14.12 secs \n",
            "epoch: 4/10\tbatch: 700/900\ttrain loss : 0.1029945721037803\ttime : 16.44 secs \n",
            "epoch: 4/10\tbatch: 800/900\ttrain loss : 0.14623152803946135\ttime : 18.77 secs \n",
            "patience_ctr : 1\n",
            "\n",
            "epoch : 4/10\t train_loss :0.14464681715307165\t validation loss : 0.15171409536556815\n",
            "\n",
            "epoch : 4/10 \t train loss : 0.10336167214786234 \t time required : 22.14 secs\n",
            "epoch: 5/10\tbatch: 0/900\ttrain loss : 0.11657164169574104\ttime : 0.34 secs \n",
            "epoch: 5/10\tbatch: 100/900\ttrain loss : 0.12440257056159329\ttime : 2.65 secs \n",
            "epoch: 5/10\tbatch: 200/900\ttrain loss : 0.10725100796330711\ttime : 4.94 secs \n",
            "epoch: 5/10\tbatch: 300/900\ttrain loss : 0.053108358922053095\ttime : 7.26 secs \n",
            "epoch: 5/10\tbatch: 400/900\ttrain loss : 0.18103808373814345\ttime : 9.58 secs \n",
            "epoch: 5/10\tbatch: 500/900\ttrain loss : 0.16137199371264377\ttime : 11.91 secs \n",
            "epoch: 5/10\tbatch: 600/900\ttrain loss : 0.09889755686212935\ttime : 14.2 secs \n",
            "epoch: 5/10\tbatch: 700/900\ttrain loss : 0.10920099896631452\ttime : 16.5 secs \n",
            "epoch: 5/10\tbatch: 800/900\ttrain loss : 0.12844584856820287\ttime : 18.85 secs \n",
            "patience_ctr : 2\n",
            "early stoppping since valid_loss > train_loss\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdHTP2-bRAQs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "317d1407-8fd2-4b25-81b9-79fc809e3ce0"
      },
      "source": [
        "st_time = time.time()\n",
        "ctr = 0\n",
        "print_every = 5\n",
        "model = model.eval()\n",
        "for x_v, y_v in test_dataloader :\n",
        "    x_v = x_v.to(device)\n",
        "    #y_v = y_v.to(device)\n",
        "   \n",
        "    op = model(x_v)\n",
        "    op = torch.argmax(F.softmax(op , dim = 1), dim = 1)\n",
        "    if ctr == 0:\n",
        "        y_pred = op\n",
        "        y_actual = y_v\n",
        "    else:\n",
        "        y_pred = torch.cat((y_pred , op))\n",
        "        y_actual = torch.cat((y_actual , y_v))\n",
        "   \n",
        "    ctr += 1\n",
        "   \n",
        "    if ctr % print_every == 0:\n",
        "        print(ctr)\n",
        "print('time taken for prediction :{} seconds'.format(time.time() - st_time ))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "10\n",
            "15\n",
            "20\n",
            "25\n",
            "30\n",
            "35\n",
            "40\n",
            "45\n",
            "50\n",
            "time taken for prediction :0.9305248260498047 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEPS5y6BRrJz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "9b8f189e-d768-4694-ba79-7ea957ed6643"
      },
      "source": [
        "def my_classification_report(y_actual , y_predicted):\n",
        "    print(classification_report(y_actual, y_pred))\n",
        "    acc = accuracy_score(y_actual , y_predicted)\n",
        "    print('accuracy : {}'.format(acc))\n",
        "   \n",
        "    conf_mat=confusion_matrix(y_actual, y_pred)\n",
        "    #print(conf_mat)\n",
        "    #plt.figure(figsize=(20,20))\n",
        "    ax = plt.subplot()\n",
        "    sns.heatmap(conf_mat, annot=True, ax = ax); #annot=True to annotate cells\n",
        "\n",
        "    # labels, title and ticks\n",
        "    ax.set_xlabel('Predicted labels')\n",
        "    ax.set_ylabel('True labels')\n",
        "    ax.set_title('Confusion Matrix')\n",
        "    ax.xaxis.set_ticklabels(['1','0'])\n",
        "    ax.yaxis.set_ticklabels(['1','0'])\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.yticks(rotation=0)\n",
        "    #plt.savefig('conf_matrix.png')\n",
        "    plt.show()\n",
        "\n",
        "y_actual = y_actual.cpu().detach().numpy()\n",
        "y_pred = y_pred.cpu().detach().numpy()\n",
        "my_classification_report(y_actual = y_actual , y_predicted = y_pred)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.96      0.94      2168\n",
            "           1       0.97      0.94      0.95      2832\n",
            "\n",
            "    accuracy                           0.95      5000\n",
            "   macro avg       0.94      0.95      0.95      5000\n",
            "weighted avg       0.95      0.95      0.95      5000\n",
            "\n",
            "accuracy : 0.9464\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAETCAYAAADAuzb1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDHG8t8jR2rE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}