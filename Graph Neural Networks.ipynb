{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report , accuracy_score , confusion_matrix , precision_score , f1_score\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn import GCNConv #GATConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils.convert import to_networkx , from_networkx\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_classification_report(y_actual , y_pred):\n",
    "    \"\"\"\n",
    "    Description : \n",
    "    - This function takes precdicted and actual values and gives key classification metrics\n",
    "    \n",
    "    Inputs:\n",
    "    1. y_actual : Array of actual labels\n",
    "    2. y_pred :  Array of predicted labels\n",
    "    \n",
    "    Outputs:\n",
    "    1. Prescision , recall, F1-Score and Accuracy metrics\n",
    "    2. Plot of confusion matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    print(classification_report(y_actual, y_pred))\n",
    "    acc = accuracy_score(y_actual , y_pred)\n",
    "    print('accuracy : {}'.format(acc))\n",
    "   \n",
    "    conf_mat=confusion_matrix(y_actual, y_pred)\n",
    "    print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs: 1\n",
      "Number of features: 1433\n",
      "Number of classes: 7\n",
      "==================================================\n",
      "Data(edge_index=[2, 10556], test_mask=[2708], train_mask=[2708], val_mask=[2708], x=[2708, 1433], y=[2708])\n",
      "Number of nodes: 2708\n",
      "Number of edges: 10556\n",
      "Number of training nodes: 140\n",
      "Training node label rate: 0.05\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "# Get some basic info about the dataset\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "print(50*'=')\n",
    "\n",
    "# There is only one graph in the dataset, use it as new data object\n",
    "data = dataset[0]  \n",
    "\n",
    "# Gather some statistics about the graph.\n",
    "print(data)\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 10556], test_mask=[2708], train_mask=[2708], val_mask=[2708], x=[2708, 1433], y=[2708])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708, 1433])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.1111, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.x.shape) # [No. Nodes x Features]\n",
    "\n",
    "# Print some of the normalized word counts of the first datapoint\n",
    "data.x[0][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 4,  ..., 3, 3, 3])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  ...,  True,  True,  True])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data.test_mask) == data.num_nodes)\n",
    "data.test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708, 1433])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(1433, 128)\n",
      "  (conv2): GCNConv(128, 128)\n",
      "  (out): Linear(in_features=128, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "        # Initialize the layers\n",
    "        self.conv1 = GCNConv(dataset.num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.out = Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # First Message Passing Layer (Transformation)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        # Second Message Passing Layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        # Output layer \n",
    "        x = F.softmax(self.out(x), dim=1)\n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=128)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = GCN(hidden_channels=64)\n",
    "\n",
    "# Use GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "data = data.to(device)\n",
    "\n",
    "# Initialize Optimizer\n",
    "learning_rate = 0.01\n",
    "decay = 5e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "                             lr=learning_rate, \n",
    "                             weight_decay=decay)\n",
    "# Define loss function (CrossEntropyLoss for Classification Problems with \n",
    "# probability distributions)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad() \n",
    "    # Use all data as input, because all nodes have node features\n",
    "    out = model(data.x, data.edge_index)  \n",
    "    # Only use nodes with labels available for loss calculation --> mask\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])  \n",
    "    loss.backward() \n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    # Use the class with highest probability.\n",
    "    pred = out.argmax(dim=1)  \n",
    "    # Check against ground-truth labels.\n",
    "    test_correct = pred[data.test_mask] == data.y[data.test_mask]  \n",
    "    # Derive ratio of correct predictions.\n",
    "    test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  \n",
    "    return pred , test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.945961594581604 , Time : 0.13 secs\n",
      "Epoch: 200, Loss: 1.2611536979675293 , Time : 4.81 secs\n",
      "Epoch: 400, Loss: 1.2241952419281006 , Time : 4.3 secs\n",
      "Epoch: 600, Loss: 1.2124096155166626 , Time : 4.36 secs\n",
      "Epoch: 800, Loss: 1.2027983665466309 , Time : 4.35 secs\n",
      "Epoch: 1000, Loss: 1.2085927724838257 , Time : 4.42 secs\n",
      "Epoch: 1200, Loss: 1.2158174514770508 , Time : 4.38 secs\n",
      "Epoch: 1400, Loss: 1.1976265907287598 , Time : 4.33 secs\n",
      "Epoch: 1600, Loss: 1.1997929811477661 , Time : 4.41 secs\n",
      "Epoch: 1800, Loss: 1.2116413116455078 , Time : 4.35 secs\n",
      "Epoch: 2000, Loss: 1.2076278924942017 , Time : 4.39 secs\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "start_time = time.time()\n",
    "for epoch in range(0, 2001):\n",
    "    loss = train()\n",
    "    losses.append(loss)\n",
    "    if epoch % 200 == 0:\n",
    "        print('Epoch: {}, Loss: {} , Time : {} secs'.format(epoch , loss , round(time.time() - start_time , 2)))\n",
    "        start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\installed_softwares\\python37\\lib\\site-packages\\seaborn\\_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses_float = [float(loss.cpu().detach().numpy()) for loss in losses] \n",
    "loss_indices = [i for i,l in enumerate(losses_float)] \n",
    "plt = sns.lineplot(loss_indices, losses_float)\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.67      0.69       130\n",
      "           1       0.70      0.86      0.77        91\n",
      "           2       0.89      0.86      0.87       144\n",
      "           3       0.88      0.79      0.83       319\n",
      "           4       0.70      0.80      0.74       149\n",
      "           5       0.80      0.78      0.79       103\n",
      "           6       0.73      0.81      0.77        64\n",
      "\n",
      "    accuracy                           0.79      1000\n",
      "   macro avg       0.77      0.79      0.78      1000\n",
      "weighted avg       0.80      0.79      0.79      1000\n",
      "\n",
      "accuracy : 0.791\n",
      "[[ 87   8   2  10  12   3   8]\n",
      " [  3  78   5   3   0   1   1]\n",
      " [  2   9 124   6   3   0   0]\n",
      " [  7  10   5 251  37   8   1]\n",
      " [ 11   5   0   9 119   3   2]\n",
      " [  6   1   4   5   0  80   7]\n",
      " [  5   0   0   2   0   5  52]]\n"
     ]
    }
   ],
   "source": [
    "my_classification_report(y_actual = data.y[data.test_mask].detach().cpu().numpy()\n",
    "                         , y_pred = pred[data.test_mask].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0500, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0500, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x[data.train_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with traditional ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(data.x[data.train_mask].detach().cpu().numpy() \n",
    "          , data.y[data.train_mask].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(data.x[data.test_mask].detach().cpu().numpy() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.42      0.47       130\n",
      "           1       0.55      0.75      0.64        91\n",
      "           2       0.49      0.81      0.61       144\n",
      "           3       0.81      0.51      0.63       319\n",
      "           4       0.48      0.58      0.53       149\n",
      "           5       0.60      0.49      0.53       103\n",
      "           6       0.49      0.56      0.52        64\n",
      "\n",
      "    accuracy                           0.57      1000\n",
      "   macro avg       0.56      0.59      0.56      1000\n",
      "weighted avg       0.61      0.57      0.57      1000\n",
      "\n",
      "accuracy : 0.573\n",
      "[[ 54  14  23   5  18   5  11]\n",
      " [  5  68   4   8   2   2   2]\n",
      " [  4   6 116   8   4   1   5]\n",
      " [ 17   9  48 163  57  16   9]\n",
      " [  8   7  25  14  86   7   2]\n",
      " [  6  12  16   4   6  50   9]\n",
      " [  6   7   7   0   5   3  36]]\n"
     ]
    }
   ],
   "source": [
    "my_classification_report(y_actual = data.y[data.test_mask].detach().cpu().numpy()\n",
    "                         , y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with traditional simple NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN(\n",
      "  (fc1): Linear(in_features=1433, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (out): Linear(in_features=64, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size , hidden_size , output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        \n",
    "        # Inputs to hidden layer linear transformation\n",
    "        self.fc1 = nn.Linear(in_features = input_size , out_features = hidden_size)\n",
    "        self.fc2 = nn.Linear(in_features = hidden_size , out_features = hidden_size)\n",
    "        self.dropout = nn.Dropout(p = 0.5)\n",
    "        \n",
    "        # Output layer\n",
    "        self.out = nn.Linear(in_features = hidden_size , out_features = output_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        #Pass output of BERT through Fully connected layer\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        #x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        #Output layer\n",
    "        x = self.out(x)\n",
    "        x = F.softmax(x , dim = 1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = SimpleNN(input_size = dataset.num_features , hidden_size = 64, output_size = dataset.num_classes)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Use GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "data = data.to(device)\n",
    "\n",
    "# Initialize Optimizer\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "                             lr=learning_rate)\n",
    "\n",
    "# Define loss function (CrossEntropyLoss for Classification Problems with \n",
    "# probability distributions)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad() \n",
    "    # Use all data as input, because all nodes have node features\n",
    "    out = model(data.x.unsqueeze(0))  \n",
    "    # Only use nodes with labels available for loss calculation --> mask\n",
    "    loss = criterion(out[: ,data.train_mask].squeeze(0) , data.y[data.train_mask])  \n",
    "    loss.backward() \n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    out = model(data.x.unsqueeze(0)) \n",
    "    # Use the class with highest probability.\n",
    "    pred = out.argmax(dim=2)  \n",
    "    # Check against ground-truth labels.\n",
    "    test_correct = pred[: , data.test_mask] == data.y[data.test_mask]  \n",
    "    # Derive ratio of correct predictions.\n",
    "    test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  \n",
    "    return pred , test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.9459106922149658 , Time : 0.02 secs\n",
      "Epoch: 100, Loss: 1.9038491249084473 , Time : 1.12 secs\n",
      "Epoch: 200, Loss: 1.9037597179412842 , Time : 1.13 secs\n",
      "Epoch: 300, Loss: 1.9036071300506592 , Time : 1.13 secs\n",
      "Epoch: 400, Loss: 1.903564691543579 , Time : 1.15 secs\n",
      "Epoch: 500, Loss: 1.9035533666610718 , Time : 1.13 secs\n",
      "Epoch: 600, Loss: 1.9035528898239136 , Time : 1.1 secs\n",
      "Epoch: 700, Loss: 1.9035208225250244 , Time : 1.15 secs\n",
      "Epoch: 800, Loss: 1.9035139083862305 , Time : 1.13 secs\n",
      "Epoch: 900, Loss: 1.9035062789916992 , Time : 1.13 secs\n",
      "Epoch: 1000, Loss: 1.9034757614135742 , Time : 1.14 secs\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "start_time = time.time()\n",
    "for epoch in range(0, 1001):\n",
    "    loss = train()\n",
    "    losses.append(loss)\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch: {}, Loss: {} , Time : {} secs'.format(epoch , loss , round(time.time() - start_time , 2)))\n",
    "        start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred , test_acc = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.10      0.16       130\n",
      "           1       0.24      0.55      0.33        91\n",
      "           2       0.18      0.58      0.27       144\n",
      "           3       0.47      0.12      0.19       319\n",
      "           4       0.43      0.06      0.11       149\n",
      "           5       0.17      0.18      0.18       103\n",
      "           6       0.21      0.28      0.24        64\n",
      "\n",
      "    accuracy                           0.23      1000\n",
      "   macro avg       0.31      0.27      0.21      1000\n",
      "weighted avg       0.35      0.23      0.20      1000\n",
      "\n",
      "accuracy : 0.23\n",
      "[[ 13  31  59   8   3   7   9]\n",
      " [  3  50  22   6   0   9   1]\n",
      " [  3  18  84   6   4  12  17]\n",
      " [  5  59 144  37   3  46  25]\n",
      " [  3  23  79  13   9  10  12]\n",
      " [  2  16  55   8   1  19   2]\n",
      " [  0  14  25   0   1   6  18]]\n"
     ]
    }
   ],
   "source": [
    "my_classification_report(y_actual = data.y[data.test_mask].detach().cpu().numpy()\n",
    "                         , y_pred = pred[:,data.test_mask].squeeze(0).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
